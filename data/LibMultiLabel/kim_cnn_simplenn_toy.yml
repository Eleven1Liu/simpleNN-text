# data
training_file: data/LibMultiLabel/train_toy.txt
test_file: data/LibMultiLabel/test_toy.txt
data_name: LEDGAR
min_vocab_freq: 1
max_seq_length: 100

# train
seed: 1337
epochs: 10
batch_size: 100
optimizer: sgd
learning_rate: 0.1
momentum : 0
weight_decay: 0
patience: 1
shuffle: false

# eval
eval_batch_size: 100
monitor_metrics: ['Micro-F1', 'Macro-F1', 'Loss', 'P@1']
val_metric: Macro-F1
val_size: 0

# model
model_name: KimCNN
network_config:
  embed_dropout: 0
  encoder_dropout: 0
  filter_sizes: [2]
  num_filter_per_size: 128 # filter channels

# pretrained vocab / embeddings
embed_file: glove.6B.100d
